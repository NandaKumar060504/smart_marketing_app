# ğŸ§  Smart Marketing App

[![Deploy to Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://streamlit.io/cloud)
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An AI-powered web app that recommends personalized advertisements and optimal pricing using contextual bandits and Q-learning. Built with **Streamlit** for a seamless, interactive user experience.


---

## ğŸ“¦ Features

- ğŸ¯ **Ad Targeting** using contextual multi-armed bandits
- ğŸ’¡ **Dynamic Pricing** powered by Q-learning (discrete environment)
- ğŸ“ˆ Learns from user feedback to improve recommendations
- ğŸ–¼ï¸ Embedded ad images
- ğŸ“ Logs interactions locally or in Firebase
- ğŸ”§ Modular codebase for easy customization

---

## ğŸ“ Project Structure

smart_marketing_app/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # Main Streamlit UI
â”‚ â”œâ”€â”€ utils.py # Utility functions
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/sample_ads.csv # Ad metadata
â”‚ â””â”€â”€ processed/logs.csv # Logs (autogenerated)
â”‚
â”œâ”€â”€ feedback/
â”‚ â””â”€â”€ logger.py # Logs user feedback
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ bandit_model.py # Contextual Bandit
â”‚
â”œâ”€â”€ q_table.pkl # Q-learning policy
â”œâ”€â”€ predict_price.py # Predict price using Q-table
â”œâ”€â”€ train_q_learning.py # Train Q-learning agent
â”œâ”€â”€ train_q_table.py # Optional Q-table script
â”œâ”€â”€ performance.py # Evaluation
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ assets/
â””â”€â”€ app_preview.png # App screenshot (add your own)


---

## ğŸš€ Local Setup

### 1. Clone the Repo
```bash
git clone https://github.com/yourusername/smart_marketing_app.git
cd smart_marketing_app

2. Virtual Enivrnoment Setup
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

3.Install Dependencies
pip install -r requirements.txt

4. Run the App
streamlit run app/main.py

## ğŸ“Š Performance & Benchmarking

- Q-learning was trained in a simulated retail environment to maximize cumulative revenue.
- Evaluation scripts (`performance.py` & `analysis.py`) generate:
  - ğŸ“ˆ **Cumulative Reward Plot**
  - ğŸ“‰ **Average Reward per Episode**
- The contextual bandit model learns in real-time from user click behavior (CTR), optimizing ad delivery dynamically.
- Benchmarking shows improved click-through rates over random baseline strategies.

---

## ğŸ”® Future Improvements

- Upgrade to more advanced contextual bandit algorithms (e.g., LinUCB, Thompson Sampling)
- Integrate deep reinforcement learning for continuous and personalized pricing
- Add user authentication and session tracking
- Cloud-based dataset and logging with Firebase or Supabase
- Real-time analytics and admin dashboards
- Mobile responsiveness and UI enhancements
- GDPR-compliant user data storage and opt-in management

---

## ğŸ‘¨â€ğŸ’» Authors

- Nanda Kumar T (https://github.com/yourusername)  
  B.Tech Computer Science and Engineering, PES University  
  Built as part of Texpidition Hackathon

- Manu Narayan Hegde ()
  B.Tech Computer Science and Engineering, PES University  
  Built as part of Texpidtion Hackthon
---



