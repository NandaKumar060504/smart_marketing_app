# 🧠 Smart Marketing App

[![Deploy to Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://streamlit.io/cloud)
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An AI-powered web app that recommends personalized advertisements and optimal pricing using contextual bandits and Q-learning. Built with **Streamlit** for a seamless, interactive user experience.


---

## 📦 Features

- 🎯 **Ad Targeting** using contextual multi-armed bandits
- 💡 **Dynamic Pricing** powered by Q-learning (discrete environment)
- 📈 Learns from user feedback to improve recommendations
- 🖼️ Embedded ad images
- 📝 Logs interactions locally or in Firebase
- 🔧 Modular codebase for easy customization

---

## 📁 Project Structure

smart_marketing_app/
│
├── app/
│ ├── main.py # Main Streamlit UI
│ ├── utils.py # Utility functions
│
├── data/
│ ├── raw/sample_ads.csv # Ad metadata
│ └── processed/logs.csv # Logs (autogenerated)
│
├── feedback/
│ └── logger.py # Logs user feedback
│
├── models/
│ └── bandit_model.py # Contextual Bandit
│
├── q_table.pkl # Q-learning policy
├── predict_price.py # Predict price using Q-table
├── train_q_learning.py # Train Q-learning agent
├── train_q_table.py # Optional Q-table script
├── performance.py # Evaluation
├── requirements.txt # Python dependencies
├── README.md
├── .gitignore
└── assets/
└── app_preview.png # App screenshot (add your own)


---

## 🚀 Local Setup

### 1. Clone the Repo
```bash
git clone https://github.com/yourusername/smart_marketing_app.git
cd smart_marketing_app

2. Virtual Enivrnoment Setup
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

3.Install Dependencies
pip install -r requirements.txt

4. Run the App
streamlit run app/main.py

## 📊 Performance & Benchmarking

- Q-learning was trained in a simulated retail environment to maximize cumulative revenue.
- Evaluation scripts (`performance.py` & `analysis.py`) generate:
  - 📈 **Cumulative Reward Plot**
  - 📉 **Average Reward per Episode**
- The contextual bandit model learns in real-time from user click behavior (CTR), optimizing ad delivery dynamically.
- Benchmarking shows improved click-through rates over random baseline strategies.

---

## 🔮 Future Improvements

- Upgrade to more advanced contextual bandit algorithms (e.g., LinUCB, Thompson Sampling)
- Integrate deep reinforcement learning for continuous and personalized pricing
- Add user authentication and session tracking
- Cloud-based dataset and logging with Firebase or Supabase
- Real-time analytics and admin dashboards
- Mobile responsiveness and UI enhancements
- GDPR-compliant user data storage and opt-in management

---

## 👨‍💻 Authors

- Nanda Kumar T (https://github.com/yourusername)  
  B.Tech Computer Science and Engineering, PES University  
  Built as part of Texpidition Hackathon

- Manu Narayan Hegde ()
  B.Tech Computer Science and Engineering, PES University  
  Built as part of Texpidtion Hackthon
---



